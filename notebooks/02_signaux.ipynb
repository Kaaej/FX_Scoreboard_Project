{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca1a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DATA_DIR: H:\\Documents\\Python\\Projet FX\\FX_Scoreboard_Project\\data\n",
      "[INFO] Rates.xlsx trouvé — chargement des taux étrangers.\n",
      "[INFO] Macro_extra.xlsx trouvé — ajout CPI/GDP supplémentaires.\n",
      "[INFO] Rates.xlsx trouvé — chargement des taux étrangers.\n",
      "[INFO] Macro_extra.xlsx trouvé — ajout CPI/GDP supplémentaires.\n",
      "[OK] Écrit : H:\\Documents\\Python\\Projet FX\\FX_Scoreboard_Project\\data\\signals_panel.csv\n",
      "[OK] Écrit : H:\\Documents\\Python\\Projet FX\\FX_Scoreboard_Project\\data\\signals_preview.csv\n",
      "\n",
      "=== Couverture des signaux (% non-NaN) ===\n",
      "        Value %  Carry %  Momentum %  Macro %  HedgeCost %\n",
      "pair                                                      \n",
      "EURCHF     81.1     67.1        86.6     81.1         85.7\n",
      "EURGBP     81.4     72.0        86.6     81.4         90.4\n",
      "EURJPY     81.4     71.1        86.6     80.7         89.4\n",
      "EURUSD     81.4     77.6        86.6     81.4         96.0\n",
      "[OK] Écrit : H:\\Documents\\Python\\Projet FX\\FX_Scoreboard_Project\\data\\signals_panel.csv\n",
      "[OK] Écrit : H:\\Documents\\Python\\Projet FX\\FX_Scoreboard_Project\\data\\signals_preview.csv\n",
      "\n",
      "=== Couverture des signaux (% non-NaN) ===\n",
      "        Value %  Carry %  Momentum %  Macro %  HedgeCost %\n",
      "pair                                                      \n",
      "EURCHF     81.1     67.1        86.6     81.1         85.7\n",
      "EURGBP     81.4     72.0        86.6     81.4         90.4\n",
      "EURJPY     81.4     71.1        86.6     80.7         89.4\n",
      "EURUSD     81.4     77.6        86.6     81.4         96.0\n"
     ]
    }
   ],
   "source": [
    "# FX Scoreboard — Notebook Signaux (version adaptée + bypass fichiers externes)\n",
    "# ------------------------------------------------------------\n",
    "# Fichiers de base attendus dans DATA_DIR :\n",
    "#   FX.xlsx    : Dates, EURUSD, EURGBP, EURCHF, EURJPY\n",
    "#   CPI.xlsx   : Dates, US_CPI, EU_CPI\n",
    "#   GDP.xlsx   : Dates, US_GDP, EU_GDP\n",
    "#   Cash.xlsx  : Dates, Cash\n",
    "# Fichiers optionnels (bypass) :\n",
    "#   Rates.xlsx       : Dates, USD_rate_1m, GBP_rate_1m, CHF_rate_1m, JPY_rate_1m\n",
    "#   Macro_extra.xlsx : Dates, UK_CPI, CH_CPI, JP_CPI, UK_GDP, CH_GDP, JP_GDP\n",
    "#\n",
    "# Sorties :\n",
    "#   signals_panel.csv   (panel complet)\n",
    "#   signals_preview.csv (10 dernières obs par paire)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings, os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- Localisation des données ----------\n",
    "def find_project_root(start=Path.cwd(), markers=(\"data\", \".git\", \"pyproject.toml\", \"README.md\")):\n",
    "    start = Path(start).resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        for m in markers:\n",
    "            if (p / m).exists():\n",
    "                return p\n",
    "    return None\n",
    "\n",
    "env_dir = os.environ.get(\"FX_DATA_DIR\") or os.environ.get(\"DATA_DIR\")\n",
    "if env_dir:\n",
    "    DATA_DIR = Path(env_dir).expanduser().resolve()\n",
    "else:\n",
    "    root = find_project_root()\n",
    "    if root:\n",
    "        DATA_DIR = (root / \"data\").expanduser().resolve()\n",
    "    else:\n",
    "        DATA_DIR = Path(r\"H:\\Documents\\Python\\Projet FX\\FX_Scoreboard_Project\\data\").expanduser().resolve()\n",
    "\n",
    "FX_FILE   = DATA_DIR / \"FX.xlsx\"\n",
    "CPI_FILE  = DATA_DIR / \"CPI.xlsx\"\n",
    "GDP_FILE  = DATA_DIR / \"GDP.xlsx\"\n",
    "CASH_FILE = DATA_DIR / \"Cash.xlsx\"\n",
    "\n",
    "_files = {\"FX\": FX_FILE, \"CPI\": CPI_FILE, \"GDP\": GDP_FILE, \"CASH\": CASH_FILE}\n",
    "_missing = [n for n, p in _files.items() if not p.exists()]\n",
    "if _missing:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Fichiers manquants dans {DATA_DIR}: {', '.join(_missing)}.\\n\"\n",
    "        f\"Soit définis FX_DATA_DIR/DATA_DIR, soit place les fichiers dans {DATA_DIR}\"\n",
    "    )\n",
    "\n",
    "print(\"Using DATA_DIR:\", DATA_DIR)\n",
    "\n",
    "# ---------- Utilitaires ----------\n",
    "def to_month_end(df, date_col=\"Dates\"):\n",
    "    df = df.rename(columns={date_col: \"Date\"}).copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True, errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Date\"]).set_index(\"Date\").sort_index()\n",
    "    return df.resample(\"M\").last()\n",
    "\n",
    "def logret(s, p=1): return np.log(s) - np.log(s.shift(p))\n",
    "def rolling_z(s, win=60, minp=24):\n",
    "    mu = s.rolling(win, min_periods=minp).mean().shift(1)\n",
    "    sd = s.rolling(win, min_periods=minp).std().shift(1)\n",
    "    return (s - mu) / sd\n",
    "def winsor(s, p1=0.05, p2=0.95): return s.clip(s.quantile(p1), s.quantile(p2))\n",
    "def z_std(s): return rolling_z(winsor(s))\n",
    "def rsi(series, window=14):\n",
    "    d = series.diff()\n",
    "    up = d.clip(lower=0).rolling(window).mean()\n",
    "    dn = (-d.clip(upper=0)).rolling(window).mean()\n",
    "    rs = up / dn\n",
    "    return 100 - (100 / (1 + rs))\n",
    "def bb_z(series, window=20):\n",
    "    ma = series.rolling(window).mean()\n",
    "    sd = series.rolling(window).std()\n",
    "    return (series - ma) / sd\n",
    "\n",
    "# ---------- 1) Chargement ----------\n",
    "fx   = to_month_end(pd.read_excel(FX_FILE),  \"Dates\")\n",
    "cpi  = to_month_end(pd.read_excel(CPI_FILE), \"Dates\")\n",
    "gdp  = to_month_end(pd.read_excel(GDP_FILE), \"Dates\")\n",
    "cash = to_month_end(pd.read_excel(CASH_FILE),\"Dates\")\n",
    "\n",
    "pairs = [c for c in [\"EURUSD\",\"EURGBP\",\"EURCHF\",\"EURJPY\"] if c in fx.columns]\n",
    "fx = fx[pairs].copy()\n",
    "\n",
    "# ---------- 2) Préparer macro de base (US/EU) ----------\n",
    "cpi_yoy = cpi[[\"US_CPI\",\"EU_CPI\"]].pct_change(12)\n",
    "cpi_yoy.columns = [\"USD_CPI_yoy\",\"EUR_CPI_yoy\"]\n",
    "\n",
    "gdp_yoy = gdp[[\"US_GDP\",\"EU_GDP\"]].pct_change(12)\n",
    "gdp_yoy.columns = [\"USD_GDP_yoy\",\"EUR_GDP_yoy\"]\n",
    "\n",
    "# ---------- 3) Taux EUR depuis Cash ----------\n",
    "cash_ret_1m = cash[\"Cash\"].pct_change()\n",
    "rate_EUR_1m = 12 * cash_ret_1m\n",
    "rates_df = pd.DataFrame({\"EUR_rate_1m\": rate_EUR_1m})\n",
    "\n",
    "# mapping devise → colonne de taux (sera complété par le bypass si Rates.xlsx existe)\n",
    "ccy_to_ratecol = {\"EUR\": \"EUR_rate_1m\", \"USD\": None, \"GBP\": None, \"CHF\": None, \"JPY\": None}\n",
    "\n",
    "# ==========================\n",
    "#      PATCH BYPASS\n",
    "# ==========================\n",
    "RATES_FILE = DATA_DIR / \"Rates.xlsx\"\n",
    "MACRO_FILE = DATA_DIR / \"Macro_extra.xlsx\"\n",
    "\n",
    "# 3.a) Tenter d'ajouter les taux étrangers depuis Rates.xlsx\n",
    "if RATES_FILE.exists():\n",
    "    print(\"[INFO] Rates.xlsx trouvé — chargement des taux étrangers.\")\n",
    "    rates_raw = to_month_end(pd.read_excel(RATES_FILE), \"Dates\")\n",
    "    for col in rates_raw.columns:\n",
    "        if col.lower().endswith(\"_rate_1m\"):\n",
    "            rates_df[col] = rates_raw[col]\n",
    "    if \"USD_rate_1m\" in rates_df.columns: ccy_to_ratecol[\"USD\"] = \"USD_rate_1m\"\n",
    "    if \"GBP_rate_1m\" in rates_df.columns: ccy_to_ratecol[\"GBP\"] = \"GBP_rate_1m\"\n",
    "    if \"CHF_rate_1m\" in rates_df.columns: ccy_to_ratecol[\"CHF\"] = \"CHF_rate_1m\"\n",
    "    if \"JPY_rate_1m\" in rates_df.columns: ccy_to_ratecol[\"JPY\"] = \"JPY_rate_1m\"\n",
    "else:\n",
    "    print(\"[INFO] Rates.xlsx absent — proxies utilisés pour rate_fore si possible.\")\n",
    "\n",
    "# 3.b) Tenter d'ajouter CPI/GDP UK/CH/JP via Macro_extra.xlsx\n",
    "cpi_yoy_full = cpi_yoy.copy()\n",
    "gdp_yoy_full = gdp_yoy.copy()\n",
    "\n",
    "if MACRO_FILE.exists():\n",
    "    print(\"[INFO] Macro_extra.xlsx trouvé — ajout CPI/GDP supplémentaires.\")\n",
    "\n",
    "    # --- CPI sheet ---\n",
    "    mac_cpi = to_month_end(pd.read_excel(MACRO_FILE, sheet_name=\"CPI\"), \"Dates\")\n",
    "    if \"UK_CPI\" in mac_cpi:\n",
    "        cpi_yoy_full[\"GBP_CPI_yoy\"] = mac_cpi[\"UK_CPI\"].pct_change(12)\n",
    "    if \"CH_CPI\" in mac_cpi:\n",
    "        cpi_yoy_full[\"CHF_CPI_yoy\"] = mac_cpi[\"CH_CPI\"].pct_change(12)\n",
    "    if \"JP_CPI\" in mac_cpi:\n",
    "        cpi_yoy_full[\"JPY_CPI_yoy\"] = mac_cpi[\"JP_CPI\"].pct_change(12)\n",
    "\n",
    "    # --- GDP sheet ---\n",
    "    mac_gdp = to_month_end(pd.read_excel(MACRO_FILE, sheet_name=\"GDP\"), \"Dates\")\n",
    "    if \"UK_GDP\" in mac_gdp:\n",
    "        gdp_yoy_full[\"GBP_GDP_yoy\"] = mac_gdp[\"UK_GDP\"].pct_change(12)\n",
    "    if \"CH_GDP\" in mac_gdp:\n",
    "        gdp_yoy_full[\"CHF_GDP_yoy\"] = mac_gdp[\"CH_GDP\"].pct_change(12)\n",
    "    if \"JP_GDP\" in mac_gdp:\n",
    "        gdp_yoy_full[\"JPY_GDP_yoy\"] = mac_gdp[\"JP_GDP\"].pct_change(12)\n",
    "\n",
    "else:\n",
    "    print(\"[INFO] Macro_extra.xlsx absent — Macro/Value non-US/EU resteront partielles.\")\n",
    "\n",
    "# ---------- 4) Construire panel long ----------\n",
    "records = []\n",
    "for col in pairs:\n",
    "    base = \"EUR\"\n",
    "    fore = col.replace(\"EUR\",\"\")\n",
    "    s = fx[col].dropna()\n",
    "    records.append(pd.DataFrame({\"pair\": col, \"base\": base, \"fore\": fore, \"spot\": s}))\n",
    "panel = pd.concat(records).sort_index()\n",
    "panel.index.name = \"Date\"\n",
    "panel = panel.reset_index().set_index([\"pair\",\"Date\"]).sort_index()\n",
    "\n",
    "# ---------- 5) Merge CPI/GDP (base=EUR, fore selon paire) ----------\n",
    "def pick(series_df, date_index, colname):\n",
    "    try:\n",
    "        return series_df.loc[date_index, colname]\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def add_macro(panel, cpi_yoy, gdp_yoy):\n",
    "    out = panel.copy()\n",
    "    base_cpi, fore_cpi, base_gdp, fore_gdp = [], [], [], []\n",
    "    for (pair, dt), row in out.iterrows():\n",
    "        fore = row[\"fore\"]\n",
    "        # CPI yoy\n",
    "        base_cpi.append(pick(cpi_yoy, dt, \"EUR_CPI_yoy\"))\n",
    "        key_cpi = f\"{fore}_CPI_yoy\" if f\"{fore}_CPI_yoy\" in cpi_yoy.columns else None\n",
    "        fore_cpi.append(pick(cpi_yoy, dt, key_cpi) if key_cpi else np.nan)\n",
    "        # GDP yoy\n",
    "        base_gdp.append(pick(gdp_yoy, dt, \"EUR_GDP_yoy\"))\n",
    "        key_gdp = f\"{fore}_GDP_yoy\" if f\"{fore}_GDP_yoy\" in gdp_yoy.columns else None\n",
    "        fore_gdp.append(pick(gdp_yoy, dt, key_gdp) if key_gdp else np.nan)\n",
    "    out[\"cpi_yoy_base\"] = base_cpi\n",
    "    out[\"cpi_yoy_fore\"] = fore_cpi\n",
    "    out[\"gdp_yoy_base\"] = base_gdp\n",
    "    out[\"gdp_yoy_fore\"] = fore_gdp\n",
    "    return out\n",
    "\n",
    "# ⚠️ on utilise les versions *full* (avec UK/CH/JP si fournis)\n",
    "panel = add_macro(panel, cpi_yoy_full, gdp_yoy_full)\n",
    "\n",
    "# ---------- 6) Taux : vrais si dispo, sinon proxies ----------\n",
    "# proxy : rate_fore ≈ rate_base + (cpi_yoy_fore - cpi_yoy_base)\n",
    "def make_rate_fore_proxy(panel_df, rates_df, cpi_yoy_df):\n",
    "    base_series = rates_df[\"EUR_rate_1m\"]\n",
    "    prox = []\n",
    "    for (pair, dt), row in panel_df.iterrows():\n",
    "        try:\n",
    "            base_rate = base_series.loc[dt]\n",
    "        except Exception:\n",
    "            base_rate = np.nan\n",
    "        cpi_b = row.get(\"cpi_yoy_base\", np.nan)\n",
    "        cpi_f = row.get(\"cpi_yoy_fore\", np.nan)\n",
    "        if pd.notna(base_rate) and pd.notna(cpi_b) and pd.notna(cpi_f):\n",
    "            prox.append(base_rate + (cpi_f - cpi_b))\n",
    "        else:\n",
    "            prox.append(np.nan)\n",
    "    return pd.Series(prox, index=panel_df.index)\n",
    "\n",
    "rate_fore_proxy = make_rate_fore_proxy(panel, rates_df, cpi_yoy_full)\n",
    "\n",
    "rates_df = rates_df.copy()\n",
    "rates_df.index = pd.to_datetime(rates_df.index)\n",
    "rates_df = rates_df.sort_index()\n",
    "\n",
    "def add_rates_with_proxy(panel_df, rates_df, ccy_to_ratecol, rate_fore_proxy):\n",
    "    out, rb, rf = panel_df.copy(), [], []\n",
    "    for (pair, dt), row in out.iterrows():\n",
    "        fore = row[\"fore\"]\n",
    "        # base\n",
    "        try: rb_val = rates_df.reindex([dt])[\"EUR_rate_1m\"].values[0]\n",
    "        except Exception: rb_val = np.nan\n",
    "        # foreign (réel si présent, sinon proxy)\n",
    "        colf = ccy_to_ratecol.get(fore)\n",
    "        if colf and colf in rates_df.columns:\n",
    "            try: rf_val = rates_df.reindex([dt])[colf].values[0]\n",
    "            except Exception: rf_val = np.nan\n",
    "        else:\n",
    "            try: rf_val = rate_fore_proxy.loc[(pair, dt)]\n",
    "            except Exception: rf_val = np.nan\n",
    "        rb.append(rb_val); rf.append(rf_val)\n",
    "    out[\"rate_base\"], out[\"rate_fore\"] = rb, rf\n",
    "    return out\n",
    "\n",
    "panel = add_rates_with_proxy(panel, rates_df, ccy_to_ratecol, rate_fore_proxy)\n",
    "\n",
    "# ---------- 7) Signaux ----------\n",
    "panel[\"ret_1m\"]  = panel.groupby(level=0)[\"spot\"].transform(logret)\n",
    "panel[\"mom_3m\"]  = panel.groupby(level=0)[\"spot\"].transform(lambda s: logret(s, 3))\n",
    "panel[\"ma_fast\"] = panel.groupby(level=0)[\"spot\"].transform(lambda s: s.rolling(3).mean())\n",
    "panel[\"ma_slow\"] = panel.groupby(level=0)[\"spot\"].transform(lambda s: s.rolling(12).mean())\n",
    "panel[\"ma_signal\"] = np.sign(panel[\"ma_fast\"] - panel[\"ma_slow\"])\n",
    "panel[\"rsi_14\"]    = panel.groupby(level=0)[\"spot\"].transform(lambda s: rsi(s, 14))\n",
    "panel[\"rsi_signal\"]= (panel[\"rsi_14\"] - 50)/50\n",
    "panel[\"z_bb\"]      = panel.groupby(level=0)[\"spot\"].transform(lambda s: bb_z(s, 20))\n",
    "\n",
    "panel[\"carry_nom_1m\"]  = panel[\"rate_fore\"] - panel[\"rate_base\"]\n",
    "panel[\"carry_real_1m\"] = (panel[\"rate_fore\"] - panel[\"cpi_yoy_fore\"]) - (panel[\"rate_base\"] - panel[\"cpi_yoy_base\"])\n",
    "panel[\"policy_bias\"]   = (panel.groupby(level=0)[\"rate_fore\"].transform(lambda s: s.rolling(2).mean())\n",
    "                          - panel.groupby(level=0)[\"rate_base\"].transform(lambda s: s.rolling(2).mean()))\n",
    "panel[\"Carry_Score_raw\"] = 0.7*panel[\"carry_real_1m\"] + 0.3*panel[\"carry_nom_1m\"]\n",
    "\n",
    "panel[\"dSpot_12m\"]  = panel.groupby(level=0)[\"spot\"].transform(lambda s: logret(s, 12))\n",
    "panel[\"dPPP_12m\"]   = panel[\"cpi_yoy_fore\"] - panel[\"cpi_yoy_base\"]\n",
    "panel[\"Value_PPP\"]  = -(panel[\"dSpot_12m\"] - panel[\"dPPP_12m\"])\n",
    "\n",
    "panel[\"gdp_yoy_diff\"]   = panel[\"gdp_yoy_fore\"] - panel[\"gdp_yoy_base\"]\n",
    "panel[\"cpi_yoy_diff\"]   = panel[\"cpi_yoy_fore\"] - panel[\"cpi_yoy_base\"]\n",
    "panel[\"Macro_Score_raw\"]= 0.5*panel[\"gdp_yoy_diff\"] + 0.5*panel[\"cpi_yoy_diff\"]\n",
    "\n",
    "panel[\"hedge_cost_1m\"]     = panel[\"rate_base\"] - panel[\"rate_fore\"]\n",
    "panel[\"HedgeCost_Score_raw\"]= -panel[\"hedge_cost_1m\"]\n",
    "\n",
    "# ---------- 8) Normalisation ----------\n",
    "for c_in, c_out in [\n",
    "    (\"Value_PPP\",\"ValueScore\"),\n",
    "    (\"Carry_Score_raw\",\"CarryScore\"),\n",
    "    (\"mom_3m\",\"Mom_mom\"),\n",
    "    (\"ma_signal\",\"Mom_ma\"),\n",
    "    (\"rsi_signal\",\"Mom_rsi\"),\n",
    "    (\"z_bb\",\"Mom_bb\"),\n",
    "    (\"Macro_Score_raw\",\"MacroScore\"),\n",
    "    (\"HedgeCost_Score_raw\",\"HedgeCostScore\"),\n",
    "]:\n",
    "    panel[c_out] = panel.groupby(level=0)[c_in].transform(z_std)\n",
    "\n",
    "panel[\"MomentumScore_raw\"] = 0.5*panel[\"Mom_mom\"] + 0.2*panel[\"Mom_ma\"] + 0.15*panel[\"Mom_rsi\"] + 0.15*panel[\"Mom_bb\"]\n",
    "panel[\"MomentumScore\"]     = panel.groupby(level=0)[\"MomentumScore_raw\"].transform(z_std)\n",
    "\n",
    "# ---------- 9) Agrégation robuste (renormalisation des poids si NaN) ----------\n",
    "score_cols = [\"ValueScore\",\"CarryScore\",\"MomentumScore\",\"MacroScore\",\"HedgeCostScore\"]\n",
    "base_w = pd.Series({\"ValueScore\":0.25,\"CarryScore\":0.25,\"MomentumScore\":0.25,\"MacroScore\":0.15,\"HedgeCostScore\":0.10})\n",
    "sub = panel[score_cols].copy()\n",
    "mask = sub.notna()\n",
    "w = pd.DataFrame([base_w]*len(sub), index=sub.index)\n",
    "w = w * mask\n",
    "w = w.div(w.sum(axis=1).replace(0, np.nan), axis=0)\n",
    "panel[\"FX_Score_raw\"] = (sub * w).sum(axis=1)\n",
    "\n",
    "panel[\"FX_Score\"]      = panel.groupby(level=0)[\"FX_Score_raw\"].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
    "panel[\"FX_Score_next\"] = panel.groupby(level=0)[\"FX_Score\"].shift(1)\n",
    "\n",
    "def hedge_from_score(s, up=0.5, dn=-0.5):\n",
    "    h = pd.Series(index=s.index, dtype=float)\n",
    "    h[s >= up] = 0.0\n",
    "    h[s <= dn] = 1.0\n",
    "    h[(s > dn) & (s < up)] = 0.5\n",
    "    return h\n",
    "\n",
    "panel[\"HedgeRatio\"] = panel.groupby(level=0)[\"FX_Score_next\"].transform(lambda s: hedge_from_score(s))\n",
    "\n",
    "# ---------- 10) Sorties ----------\n",
    "keep = [\n",
    "    \"base\",\"fore\",\"spot\",\"ret_1m\",\n",
    "    \"rate_base\",\"rate_fore\",\"carry_nom_1m\",\"carry_real_1m\",\"policy_bias\",\"CarryScore\",\n",
    "    \"cpi_yoy_base\",\"cpi_yoy_fore\",\"dSpot_12m\",\"dPPP_12m\",\"Value_PPP\",\"ValueScore\",\n",
    "    \"mom_3m\",\"ma_fast\",\"ma_slow\",\"ma_signal\",\"rsi_14\",\"rsi_signal\",\"z_bb\",\"MomentumScore\",\n",
    "    \"gdp_yoy_base\",\"gdp_yoy_fore\",\"gdp_yoy_diff\",\"cpi_yoy_diff\",\"MacroScore\",\n",
    "    \"hedge_cost_1m\",\"HedgeCostScore\",\n",
    "    \"FX_Score\",\"FX_Score_next\",\"HedgeRatio\"\n",
    "]\n",
    "out = panel[keep].copy().reset_index()\n",
    "\n",
    "out_full = DATA_DIR / \"signals_panel.csv\"\n",
    "out_prev = DATA_DIR / \"signals_preview.csv\"\n",
    "out.to_csv(out_full, index=False)\n",
    "out.groupby(\"pair\").tail(10).to_csv(out_prev, index=False)\n",
    "print(f\"[OK] Écrit : {out_full}\\n[OK] Écrit : {out_prev}\")\n",
    "\n",
    "# ---------- 11) Diagnostic ----------\n",
    "diag = (panel[[\"Value_PPP\",\"Carry_Score_raw\",\"MomentumScore_raw\",\"Macro_Score_raw\",\"HedgeCost_Score_raw\"]]\n",
    "        .notna()\n",
    "        .groupby(level=0)\n",
    "        .mean()\n",
    "        .rename(columns={\"Value_PPP\":\"Value %\",\"Carry_Score_raw\":\"Carry %\",\"MomentumScore_raw\":\"Momentum %\",\"Macro_Score_raw\":\"Macro %\",\"HedgeCost_Score_raw\":\"HedgeCost %\"})\n",
    "        * 100).round(1)\n",
    "print(\"\\n=== Couverture des signaux (% non-NaN) ===\")\n",
    "print(diag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_fx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
